<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>Project III</title>
  
  <style type="text/css">
  body { margin-left: 5%;
    margin-right: 5%; margin-top: 5%;
    font-family: sans-serif }
  </style></head><body bgcolor="#fdfde6">
<h3 align="center">Project III</h3>
<hr width="70%">
<h2 align="center">Bootstrap <br></h2>

<table align="center" bgcolor="#fffff5" border="0" cellpadding="10" width="65%">
  <tbody>
    <tr>
      <td>
      <h4>Description</h4>

  <p>   The bootstrap is a computer-intensive method introduced by Efron in 1979. It is a resampling technique for obtaining estimates of properties of statistical estimators without making assumptions about the underlying distribution of the data, e.g. to find standard errors of estimates, confidence intervals for unknown parameters, and other measures of accuracy. 
Bootstrap has received much attention over the past decades due to its simplicity and ability to adapt to general data structures.
  </p> 
      
          <blockquote>    
 “The bootstrap has shown us how to use the power of the computer and iterated calculations to go where theoretical calculations cannot, which introduces a different way of thinking about all of statistics.” (G. Casella, 2003)

          </blockquote>
<p> 
      
There are many interesting topics you can choose from, to name a few; </p>
          <ul>
<li> Bootstrap for Dependent data and time series, Block bootstrap.</li>
<li> Bootstrap for Censored data </li>
<li> Bootstrap for Heavy-tailed data and extremes</li>
<li> Bootstrap for Spatial data</li>
<li> Bootstrap Bioequivalence</li>
<li> Bootstrap in Machine learning (bagging and boosting).</li>

</ul>


    

<h4>Prerequisites</h4>
<ul style="list-style: none;">
    <li>Statistical Concepts II </li>
    <li>Monte Carlo II (recommended but not required) </li>
    <li>Familiarity with the statistical software R </li>
</ul>
<h4>Corequisites </h4>
    
<p>Statistical Methods III (recommended)</p>

    
    
<h4>References</h4>
<ul>
<li>Efron, B. Bootstrap Methods: Another Look at the Jackknife. Ann. Statist. 7, 1-26, 1979. </li>
<li> Efron, B. and Tibshirani, R. Bootstrap Methods for Standard Errors, Confidence Intervals, and Other Measures of Statistical Accuracy. Statist. Sci. 1, 54-75, 1986. </li>
<li> Efron, B. Censored Data and the Bootstrap. Journal of the American Statistical Association, 76, 312- 319, 1981.</li>
<li> Lahiri, S.N. Resampling Methods for Dependent Data. Springer Verlag Inc, 2003.</li>

<li> Davison, A.C. and Hinkley, D.V. Bootstrap Methods and Their Application. Cambridge University Press, 1997.</li>
<li> Efron, B. and Tibshirani, R. An Introduction to the Bootstrap. Chapman &amp; Hall, 1993.</li>
<li> Breiman, L. Bagging predictors. Machine Learning. 24, 123–140, 1996. </li>

</ul>




</td>
    </tr>
  </tbody>
</table>
<p align="center"><font size="-1"><i> email: <a href="mailto:P.S.Craig@durham.ac.uk">Peter Craig </a>/ <a href="mailto:tahani.maturi@durham.ac.uk">Tahani Coolen-Maturi</a> </i></font></p>
<hr width="70%">
<p align="center"><a href="https://www.maths.dur.ac.uk/projects">Back</a></p>
</body></html>
